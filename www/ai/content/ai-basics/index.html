<!doctype html>
<!--
    Mozilla AI Guide |
    We need your help to make OSS AI best-in-class!  
    Reach out to ai-guide@mozilla.com to contribute! 
    
    This Source Code Form is subject to the terms of the Mozilla Public License, v. 2.0. If a copy of the MPL was not distributed with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
-->
<html lang="en" data-theme="moz_ai_guide_base">
  <head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Mozilla AI Guide</title>
    <meta name="description" content="Mozilla AI Guide" />

    <meta property="og:type" content="website" />
    <meta property="og:site_name" content="Mozilla" />
    <meta property="og:image" content="/img/mozilla-256.jpg" />
    <meta property="og:title" content="Mozilla AI Guide" />
    <meta property="og:description" content="Mozilla AI Guide" />
    <meta name="twitter:card" content="summary" />
    <meta name="twitter:site" content="@mozilla" />
    <meta name="twitter:domain" content="future.mozilla.org" />

    <link rel="stylesheet" href="/css/ai.e9ce9d34.css" />
    <script
      type="text/javascript"
      src="/scripts/dark_mode.ce5d9712.js"
    ></script>
  </head>
  <body>
    <div class="drawer lg:drawer-open">
      <input id="my-drawer-2" type="checkbox" class="drawer-toggle" />
      <!-- <div class="drawer-content flex flex-col items-center justify-center relative"> -->
      <div class="drawer-content">
        <div id="mobile_banner">
          <label id="hamburger-btn" class="" for="my-drawer-2">
            <svg
              viewBox="0 0 100 80"
              width="20"
              height="20"
              fill="currentColor"
            >
              <rect width="100" height="10" rx="8"></rect>
              <rect y="30" width="80" height="10" rx="8"></rect>
              <rect y="60" width="60" height="10" rx="8"></rect>
            </svg>
          </label>

          <div id="header-bg">
            <div id="header-content">
              <a href="/ai/home">
                <h1 id="header-title">AI Guide</h1>
              </a>
            </div>
          </div>
        </div>
        <main id="content" class="">
          <h2 id="ai-basics" tabindex="-1">AI Basics</h2>
          <h3 id="what-is-ai-in-2023" tabindex="-1">What is AI in 2023?</h3>
          <p>
            Artificial intelligence (AI), machine learning (ML), large language
            models (LLMs) and related technologies and techniques have crossed
            the chasm from science fiction and niche research domains into
            widespread awareness and widely adopted products, services, and
            systems in 2023.
          </p>
          <p>
            Although the history of AI research reaches back to the 1950s, the
            current widespread awareness of AI can be traced to a recent set of
            products and services using generative AI such as ChatGPT, Stable
            Diffusion, and the like. In particular, OpenAI’s ChatGPT captured
            the imagination of many by removing many technical barriers to
            interacting with AI through “natural language” text conversations.
            As such, ChatGPT allowed individuals to see the power, promise, and
            pitfalls of such systems, and many heralded the moment as a new
            epoch in the history of computing.
          </p>
          <p>
            The rapid popularity of ChatGPT and other systems meant new
            attention and investment in the domain. Almost overnight, new
            applications and companies emerged that sought to make use of these
            technologies in new ways and new domains. As a result, a myriad of
            industries are finding new ways to use this technology for better
            decision-making, automation, and innovation.
          </p>
          <p>
            Alongside this expansion in interest and development is the need for
            individuals in a variety of roles to quickly ramp up their
            understanding of AI. However, with the increasing complexity of
            these models, the substantial amount of new things to learn and the
            extensive list of new libraries being added every single day,
            onboarding into the state-of-the-art AI world has become challenging
            for new engineers. While resources exist, many of these resources
            (and increasingly so) depend on proprietary technologies. Moreover,
            the state of knowledge is rapidly changing, and existing resources
            are quickly out-of-date.
          </p>
          <h3 id="why-are-people-excited-about-llms" tabindex="-1">
            Why are people excited about LLMs?
          </h3>
          <p>
            Large Language Models (LLMs) are AI models that use deep learning
            techniques to process and understand natural language text. These
            models have millions or even billions of parameters that allow them
            to generate human-like language output, making them ideal for tasks
            such as language translation, natural-sounding chatbots, document
            and code generation, and more. LLMs have been trained on massive
            amounts of data, allowing them to identify patterns in language that
            were previously difficult for computers to comprehend. This has led
            to breakthroughs in natural language processing, generated output
            and improved communication between humans and machines.
          </p>
          <h3 id="why-are-people-concerned-about-llms" tabindex="-1">
            Why are people concerned about LLMs?
          </h3>
          <p>
            LLMs are currently used to power chatbots and a wide variety of
            content tools that can generate text, images, video, and even code.
            But the very traits that make LLMs so powerful and useful also
            present important questions that technologists need to consider when
            developing and deploying them.
          </p>
          <p>
            By mimicking human language and creativity, LLMs have the potential
            to transform or even automate certain tasks or jobs. The mass
            harvesting of data to train these systems presents largely
            unresolved challenges to the principles of copyright, fair use, and
            fair compensation. The tendency of users to view LLM-powered tools
            as “officious oracles” can lead humans to make flawed or harmful
            decisions based on the biases and misinformation these systems can
            produce.
          </p>
          <p>
            At Mozilla, we believe that developers should take these risks
            seriously and cultivate both an understanding and awareness of how
            their chosen AI technologies behave and impact the world. By their
            very nature, open source LLMs offer a greater chance to achieve
            those goals.
          </p>
          <h3 id="what-exactly-is-an-llm" tabindex="-1">
            What exactly is an LLM?
          </h3>
          <p>
            At its heart, a Transformer-based Large Language Model (LLM) is
            essentially a computer program designed to generate text that
            resembles human-written content. It leverages machine learning
            techniques, specifically a type of neural network called a
            Transformer. At a high-level, a Transformer encodes linguistic
            patterns in the form of statistical relationships between words, and
            then uses those patterns to generate text. Transformers encode these
            semantic patterns by ingesting examples of existing text. Now let’s
            dig a little deeper.
          </p>
          <p><strong>Here’s how it works:</strong></p>
          <div class="whitespace-nowrap overflow-x-scroll flex py-6">
            <div
              id="item1"
              class="card card-compact bg-neutral w-72 shrink-0 grow-0 ml-6 first:ml-0"
            >
              <figure class="card-figure !mt-0 !mb-0">
                <img
                  src="/img/ai/carousels/how-llm-works/tokenization.png"
                  alt="Tokenization Visualization"
                />
              </figure>
              <div class="card-body text-neutral-content whitespace-normal">
                <div class="font-semibold mb-0">Tokenization</div>
                <p>
                  The LLM starts by breaking down the input text, or
                  &#39;prompt&#39;, into smaller pieces known as tokens. These
                  could be as small as one character or as large as one word
                </p>
              </div>
            </div>
          </div>
          <div class="whitespace-nowrap overflow-x-scroll flex py-6">
            <div
              id="item1"
              class="card card-compact bg-neutral w-72 shrink-0 grow-0 ml-6 first:ml-0"
            >
              <figure class="card-figure !mt-0 !mb-0">
                <img
                  src="/img/ai/carousels/how-llm-works/tokenization.png"
                  alt="Tokenization Visualization"
                />
              </figure>
              <div class="card-body text-neutral-content whitespace-normal">
                <div class="font-semibold mb-0">Tokenization</div>
                <p>
                  The LLM starts by breaking down the input text, or
                  &#39;prompt&#39;, into smaller pieces known as tokens.
                </p>
              </div>
            </div>
            <div
              id="item2"
              class="card card-compact bg-neutral w-72 shrink-0 grow-0 ml-6 first:ml-0"
            >
              <figure class="card-figure !mt-0 !mb-0">
                <img
                  src="/img/ai/carousels/how-llm-works/embedding.png"
                  alt="Embedding Visualization"
                />
              </figure>
              <div class="card-body text-neutral-content whitespace-normal">
                <div class="font-semibold mb-0">Embedding</div>
                <p>
                  Next, each token is converted into a numerical representation
                  through a process called embedding.
                </p>
              </div>
            </div>
            <div
              id="item3"
              class="card card-compact bg-neutral w-72 shrink-0 grow-0 ml-6 first:ml-0"
            >
              <figure class="card-figure !mt-0 !mb-0">
                <img
                  src="/img/ai/carousels/how-llm-works/self-attention.png"
                  alt="Self-attention Visualization"
                />
              </figure>
              <div class="card-body text-neutral-content whitespace-normal">
                <div class="font-semibold mb-0">Self-attention</div>
                <p>
                  The model then adds additional information to these vectors to
                  account for the order of words in the input. Self attention
                  mechanisms allow the model to create context-aware
                  representations of each word.
                </p>
              </div>
            </div>
            <div
              id="item4"
              class="card card-compact bg-neutral w-72 shrink-0 grow-0 ml-6 first:ml-0"
            >
              <figure class="card-figure !mt-0 !mb-0">
                <img
                  src="/img/ai/carousels/how-llm-works/decoding.png"
                  alt="Decoding Visualization"
                />
              </figure>
              <div class="card-body text-neutral-content whitespace-normal">
                <div class="font-semibold mb-0">Decoding</div>
                <p>
                  The LLM Decoder will take the output and use it to predict the
                  next token in the sequence.
                </p>
              </div>
            </div>
            <div
              id="item5"
              class="card card-compact bg-neutral w-72 shrink-0 grow-0 ml-6 first:ml-0"
            >
              <figure class="card-figure !mt-0 !mb-0">
                <img
                  src="/img/ai/carousels/how-llm-works/output.png"
                  alt="Output Visualization"
                />
              </figure>
              <div class="card-body text-neutral-content whitespace-normal">
                <div class="font-semibold mb-0">Output</div>
                <p>Finally, the model generates a response.</p>
              </div>
            </div>
          </div>
          <p>
            The LLM starts by breaking down the input text, or “prompt,” into
            smaller pieces known as tokens. These could be as small as one
            character or as large as one word.
          </p>
          <p>
            Next, each token is converted into a numerical representation
            through a process called embedding. This transformation turns each
            word into a high-dimensional vector in order to capture the semantic
            relationship of words.
          </p>
          <p>
            The model then adds additional information to these vectors to
            account for the order of words in the input. This is crucial because
            the meaning of a sentence can change dramatically based on word
            order.
          </p>
          <p>
            Now comes the real magic of the Transformer architecture:
            self-attention mechanisms. These allow the model to weigh the
            importance of different words when predicting the next word in the
            sentence. This way, the model can create context-aware
            representations of each word.
          </p>
          <p>
            If the LLM includes a decoder component, it will take the output
            from the encoder and use it, along with the previously generated
            tokens, to predict the next token in the sequence.
          </p>
          <p>
            Finally, the model generates a response, one token at a time, until
            it reaches a certain length or produces a termination token.
          </p>
          <p>
            All these steps involve complex mathematical operations and
            transformations. But fundamentally, what the model is doing is
            learning patterns in the data it was trained on, and using those
            patterns to generate new text that fits within the same patterns.
          </p>
          <p>
            So, in essence, a Transformer-based LLM is a cleverly designed
            pattern recognition system that uses learned associations between
            words to generate human-like text. It’s like having a scribe who has
            read everything ever written and can produce text on any topic in a
            style that mirrors the content it was trained on.
          </p>
          <h3 id="what-are-the-pros-and-cons-of-using-an-llm" tabindex="-1">
            What are the pros &amp; cons of using an LLM?
          </h3>
          <p>
            Although LLMs have made it possible for computers to process human
            language ways that have been previously difficult, if not
            impossible, they are not without trade-offs:
          </p>
          <ul>
            <li>
              Pros
              <ul>
                <li>
                  <strong>Improved Accuracy</strong>: LLMs are trained on large
                  amounts of human-readable data (e.g. written text, code, and
                  audio) and rely on state-of-the-art techniques to determine
                  patterns within those data. The size and pattern recognition
                  techniques (e.g. Transformers) improve the accuracy of
                  predictions over previous systems.
                </li>
                <li>
                  <strong>Efficiency</strong>: With LLMs, tasks such as language
                  translation and chatbots can be automated, freeing up time for
                  humans to focus on more complex tasks.
                </li>
                <li>
                  <strong>Language Generation</strong>: LLMs can generate
                  human-like language output, making them applicable for tasks
                  such as content creation and copywriting.
                </li>
              </ul>
            </li>
            <li>
              Cons
              <ul>
                <li>
                  <strong>Computational Power Requirements</strong>: Training an
                  LLM requires significant computational power, which can be
                  expensive and time-consuming.
                </li>
                <li>
                  <strong>Data Bias</strong>: Because LLMs are trained on
                  massive amounts of data, they can perpetuate biases that exist
                  in the training data.
                </li>
                <li>
                  <strong>Lack of Transparency</strong>: The inner workings of
                  an LLM can be difficult to understand, which makes it
                  challenging to identify how it arrived at a particular
                  decision or prediction.
                </li>
                <li>
                  <strong>LLM hallucinations</strong>: One of the most
                  interesting and controversial aspects of LLMs is their ability
                  to generate realistic language output that they have never
                  been trained on. This phenomenon is known as LLM
                  hallucination, and it has raised concerns about the potential
                  misuse of these models.
                </li>
              </ul>
            </li>
          </ul>
          <h3 id="what-new-behaviors-do-llms-unlock" tabindex="-1">
            What new behaviors do LLMs unlock?
          </h3>
          <p>
            Large Language Models (LLMs) have unlocked a plethora of new
            behaviors that were previously impossible for computers to achieve.
            For example, LLMs can now generate highly convincing human-like
            text, which has led to the development of more advanced chatbots and
            virtual assistants. Additionally, LLMs have revolutionized the field
            of natural language processing by enabling machines to understand
            and interpret complex human language in ways that were previously
            impossible. This has opened up new possibilities for automated
            language translation, content creation, code generation, and even
            sentiment analysis. With continued advancements in LLM technology,
            we can expect to see even more exciting developments in the near
            future.
          </p>
          <h3
            id="what-are-the-components-of-transformer-based-pre-trained-llms"
            tabindex="-1"
          >
            What are the components of Transformer-based, pre-trained LLMs?
          </h3>
          <ul>
            <li>
              <strong>Tokenizer</strong>: This is the first step in processing
              text data. The tokenizer converts raw text into chunks known as
              ‘tokens’. These tokens can represent words, subwords, or even
              characters depending on the granularity of the tokenization
              process. For instance, a word-level tokenizer will convert the
              sentence “I love coding” into ‘I’, ‘love’, ‘coding’.
            </li>
            <li>
              <strong>Embedding Layer</strong>: Once the text is tokenized,
              these tokens are transformed into dense vectors of fixed size in a
              high-dimensional space through the embedding layer. These
              embeddings capture semantic information about the words. For
              example, in this space, ‘king’ and ‘queen’ would be closer to each
              other than ‘king’ and ‘apple’.
            </li>
            <li>
              <strong>Encoder</strong>: The encoder processes the input sequence
              into a context-dependent representation that captures the meaning
              of the text. It uses a Transformer architecture which allows it to
              pay varying levels of ‘attention’ to different parts of the input
              sequence at each step of the encoding process. The output of the
              encoder is a series of hidden states.
            </li>
            <li>
              <strong>Decoder</strong>: The decoder generates output text word
              by word based on the hidden states from the encoder. In some
              models like GPT-3, the decoder is essentially the entire model. It
              also uses a Transformer architecture and attention mechanism to
              focus on the relevant parts of the input.
            </li>
            <li>
              <strong>Attention Mechanism</strong>: This is a key part of both
              the encoder and decoder in a Transformer. It helps the model
              dynamically focus on different parts of the input sequence as it
              processes the data. It computes a weighted sum of input values (or
              ‘query’) based on their relevance (or ‘attention scores’) to the
              current ‘key’ value.
            </li>
            <li>
              <strong>Pre-training and Fine-tuning</strong>: LLMs often start
              with a pre-trained language model, which have been trained on vast
              amounts of text data. These models are then fine-tuned for
              specific tasks. During fine-tuning, the model learns task-specific
              patterns on top of the general language understanding it gained
              during pre-training.
            </li>
          </ul>
          <h3
            id="when-i-send-a-transformer-based-llm-a-prompt-what-happens-internally-in-more-technical-terms"
            tabindex="-1"
          >
            When I send a Transformer-based LLM a “prompt”, what happens
            internally in more technical terms?
          </h3>
          <ol>
            <li>
              <strong>Tokenization</strong>: The prompt is first converted into
              tokens (smaller units of text) using a process called
              tokenization. This could be as small as words, or even subwords in
              some cases.
            </li>
            <li>
              <strong>Embedding</strong>: Each token is then mapped to a
              high-dimensional vector using a pre-trained embedding layer. This
              representation, known as a word vector, captures semantic
              information about the token in its dimensions.
            </li>
            <li>
              <strong>Positional Encoding</strong>: Since transformer models do
              not inherently understand the order of tokens, positional encoding
              is added to give sequence information to the model. This involves
              adding a vector to the embedding which represents the position of
              each token within the sequence.
            </li>
            <li>
              <strong>Encoder</strong>: The encoded input is passed through
              several layers (the exact number depends on the model
              architecture). Each layer consists of self-attention mechanisms
              and feed-forward neural networks. These layers allow the model to
              consider all parts of the input when generating each part of the
              output.
            </li>
            <li>
              <strong>Decoder (if applicable)</strong>: Some transformer models,
              like BERT, are ‘encoder-only’, while others, like T5, also include
              a decoder component. The decoder takes the output of the encoder
              and generates the final output text. It also uses the attention
              mechanism, but in a slightly different way that allows it to
              consider previously generated output tokens.
            </li>
            <li>
              <strong>Output Generation</strong>: Finally, the model generates
              the output text. This is done one token at a time, with the model
              deciding on the most likely next token based on the current state.
              The process continues until the model generates a termination
              token or reaches a preset maximum length.
            </li>
          </ol>
          <p>
            Each step in this process involves complex mathematical operations
            and transformations. But at a high-level, the goal is to convert
            text into a form that the model can understand, let the model
            process and generate a response, and then convert that response back
            into human-readable text.
          </p>
          <div class="text-right">
            <a class="button-next-page" href="/ai/content/llms-101/"
              >LLMs 101 &rarr;</a
            >
          </div>
        </main>
        <footer id="footer" class="mzp-c-footer">
          <div class="mzp-l-content">
            <nav class="mzp-c-footer-secondary">
              <div class="container">
                <ul class="mzp-c-footer-terms">
                  <li>
                    <a
                      href="https://www.mozilla.org/privacy/websites/"
                      data-link-type="footer"
                      data-link-name="Privacy"
                      >Website Privacy Notice</a
                    >
                  </li>
                  <li>
                    <a
                      href="https://www.mozilla.org/privacy/websites/#user-choices"
                      data-link-type="footer"
                      data-link-name="Cookies"
                      >Cookies</a
                    >
                  </li>
                  <li>
                    <a
                      href="https://www.mozilla.org/about/legal/"
                      data-link-type="footer"
                      data-link-name="Legal"
                      >Legal</a
                    >
                  </li>
                  <li>
                    <a
                      href="https://www.mozilla.org/about/governance/policies/participation/"
                      data-link-type="footer"
                      data-link-name="Community Participation Guidelines"
                      >Community Participation Guidelines</a
                    >
                  </li>
                  <li>
                    <a
                      href="https://www.mozilla.org/about/this-site/"
                      data-link-type="footer"
                      data-link-name="About this site"
                      >About this site</a
                    >
                  </li>
                </ul>
              </div>
              <div class="container">
                <div class="mzp-c-footer-license leading-6" rel="license">
                  Visit
                  <a href="https://www.mozilla.org/" class="underline"
                    >Mozilla Corporation’s</a
                  >
                  not-for-profit parent, the
                  <a
                    href="https://foundation.mozilla.org/?utm_source=www.mozilla.org&amp;utm_medium=referral&amp;utm_campaign=footer"
                    class="underline"
                    rel="external noopener"
                    >Mozilla Foundation</a
                  >. Portions of this content are ©1998–2023 by individual
                  mozilla.org contributors. Content available under a
                  <a
                    rel="license"
                    href="https://www.mozilla.org/foundation/licensing/website-content/"
                    >Creative Commons license</a
                  >.
                </div>
              </div>
            </nav>
          </div>
        </footer>
      </div>
      <div class="drawer-side">
        <label for="my-drawer-2" class="drawer-overlay"></label>
        <!-- <button id="sidebar-close-btn" class="drawer-button">X</button> -->

        <ul class="menu">
          <li>
            <a href="/ai/home"
              ><img
                alt="Mozilla logo"
                class="dark:[filter:invert(1)]"
                id="sidebar-logo"
                src="/img/mozilla-only.c3f76b0f.png"
            /></a>
          </li>
          <li>
            <details closed="">
              <summary>
                <a href="/ai/content/introduction/">Introduction</a>
              </summary>
              <ul class="sub_menu">
                <li>
                  <a href="/ai/content/introduction/#why-this-guide"
                    >Why this guide?</a
                  >
                </li>
                <li>
                  <a href="/ai/content/introduction/#why-mozilla"
                    >Why Mozilla?</a
                  >
                </li>
              </ul>
            </details>
          </li>
          <li>
            <details closed="">
              <summary>
                <a href="/ai/content/ai-basics/">AI Basics</a>
              </summary>
              <ul class="sub_menu">
                <li>
                  <a href="/ai/content/ai-basics/#what-is-ai-in-2023"
                    >What is AI in 2023?</a
                  >
                </li>
                <li>
                  <a
                    href="/ai/content/ai-basics/#why-are-people-excited-about-llms"
                    >Why are people excited about LLMs?</a
                  >
                </li>
                <li>
                  <a
                    href="/ai/content/ai-basics/#why-are-people-concerned-about-llms"
                    >Why are people concerned about LLMs?</a
                  >
                </li>
                <li>
                  <a href="/ai/content/ai-basics/#what-exactly-is-an-llm"
                    >What exactly is an LLM?</a
                  >
                </li>
                <li>
                  <a
                    href="/ai/content/ai-basics/#what-are-the-pros-cons-of-using-an-llm"
                    >What are the pros &amp; cons of using an LLM?</a
                  >
                </li>
                <li>
                  <a
                    href="/ai/content/ai-basics/#what-new-behaviors-do-llms-unlock"
                    >What new behaviors do LLMs unlock?</a
                  >
                </li>
                <li>
                  <a
                    href="/ai/content/ai-basics/#what-are-the-components-of-transformer-based-pre-trained-llms"
                    >What are the components of Transformer-based, pre-trained
                    LLMs?</a
                  >
                </li>
                <li>
                  <a
                    href="/ai/content/ai-basics/#when-i-send-a-transformer-based-llm-a-prompt-what-happens-internally-in-more-technical-terms"
                    >When I send a Transformer-based LLM a “prompt”, what
                    happens internally in more technical terms?</a
                  >
                </li>
              </ul>
            </details>
          </li>
          <li>
            <details closed="">
              <summary>
                <a href="/ai/content/llms-101/">LLMs 101</a>
              </summary>
              <ul class="sub_menu">
                <li>
                  <a
                    href="/ai/content/llms-101/#what-do-these-numbers-mean-in-the-names-of-models"
                    >What do these numbers mean in the names of models?</a
                  >
                </li>
                <li>
                  <a href="/ai/content/llms-101/#what-is-a-parameter"
                    >What is a parameter?</a
                  >
                </li>
                <li>
                  <a href="/ai/content/llms-101/#what-does-training-an-llm-mean"
                    >What does “training” an LLM mean?</a
                  >
                </li>
                <li>
                  <a
                    href="/ai/content/llms-101/#how-does-a-typical-training-run-work"
                    >How does a typical training run work?</a
                  >
                </li>
                <li>
                  <a href="/ai/content/llms-101/#what-is-backpropagation"
                    >What is backpropagation?</a
                  >
                </li>
                <li>
                  <a
                    href="/ai/content/llms-101/#what-does-fine-tuning-an-llm-mean"
                    >What does “fine-tuning” an LLM mean?</a
                  >
                </li>
                <li>
                  <a href="/ai/content/llms-101/#human-in-the-loop-approach"
                    >“Human in the loop” approach</a
                  >
                </li>
                <li>
                  <a href="/ai/content/llms-101/#what-does-inference-mean"
                    >What does "inference" mean?</a
                  >
                </li>
                <li>
                  <a
                    href="/ai/content/llms-101/#is-inference-computationally-expensive"
                    >Is inference computationally expensive?</a
                  >
                </li>
                <li>
                  <a href="/ai/content/llms-101/#what-is-a-vector"
                    >What is a vector?</a
                  >
                </li>
                <li>
                  <a href="/ai/content/llms-101/#what-is-beam-search"
                    >What is beam search?</a
                  >
                </li>
                <li>
                  <a href="/ai/content/llms-101/#what-is-sampling"
                    >What is sampling?</a
                  >
                </li>
                <li>
                  <a href="/ai/content/llms-101/#what-is-temperature"
                    >What is temperature?</a
                  >
                </li>
              </ul>
            </details>
          </li>
          <li class="upcoming">
            <a disabled="">
              <div class="badge">Up Next</div>
              Choosing ML models</a
            >
          </li>
          <li class="upcoming">
            <a disabled="">
              <div class="badge">Up Next</div>
              Fine-tuning</a
            >
          </li>
          <li class="upcoming">
            <a disabled="">
              <div class="badge">Up Next</div>
              LLMs from scratch</a
            >
          </li>
          <li class="upcoming">
            <a disabled="">
              <div class="badge">Up Next</div>
              Images, Audio &amp; Video</a
            >
          </li>
        </ul>
      </div>
      <script type="text/javascript">
        const sidebarDrawer = document.getElementById("my-drawer-2");
        document.querySelectorAll("ul.menu li a").forEach(function (item) {
          item.addEventListener("click", function () {
            sidebarDrawer.checked = false;
            return true;
          });
        });
      </script>
    </div>
  </body>
</html>
